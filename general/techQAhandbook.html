<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../style.css">
    <title>techQA questions</title>
    <title>Document</title>
</head>
<body>
    <p class="question">What is graphQL APIs and how it differs from REST APIs?</p>
    <p class="answer">GraphQL is a schema-based API style where the client decides exactly what data it wants and in what shape it wants it. Instead of exposing many URLs like REST, a GraphQL server exposes a single endpoint. The client sends a query that lists all the fields it needs, and the server returns only those fields. The GraphQL schema defines all types and fields available, acting like a shared contract between frontend and backend. Each field in the schema is resolved by a function called a resolver, which fetches data from databases or microservices.<br>GraphQL provides three main operations. A query is used to fetch data and works like a GET in REST, except the client can choose the exact fields to fetch. A mutation is used to modify data—similar to POST/PUT/DELETE in REST—but again, the client controls the returned fields. A subscription is used for real-time updates, allowing the server to push data to the client whenever something changes, which is harder to achieve with REST without extra protocols.<br>GraphQL differs from REST mainly in how data is fetched. REST organizes APIs around resource-based URLs such as <span style="background-color: aliceblue;">/users</span> or <span style="background-color: aliceblue;">/orders/{id}</span>, and each endpoint returns a fixed response. If the client needs more or different data, it often needs multiple calls or ends up downloading unnecessary fields. GraphQL avoids this by letting the client combine everything it needs in one request and ask for only the required fields. This solves the common problems of over-fetching and under-fetching.<br>GraphQL is especially helpful when clients have very different data needs. Mobile apps can reduce bandwidth by fetching only tiny slices of data. Dashboards or modern frontends can request complex nested data in one go. In microservice architectures, a GraphQL gateway can collect data from many services and return a unified response, so clients don't need to know about the internal service structure.<br>There are challenges too. Without careful design, GraphQL resolvers can accidentally cause N+1 problems where the server makes too many backend calls. Tools like DataLoader help batch and cache requests to prevent this. Caching is more complex than REST because all GraphQL requests hit one endpoint and their shapes vary, which makes traditional HTTP caching less useful. Authorization often must be handled at field level rather than endpoint level, which requires more careful design. GraphQL queries also need limits because clients can send deeply nested or expensive queries; persisted queries, depth limits, and cost rules help control this. The good part is that GraphQL schema evolution is easy: you can add new fields without breaking existing clients, and you rarely need versioning.<br/>REST still works better when your data is simple, resource-based, easy to cache, and when you want full advantage of HTTP features. It's predictable, easy to reason about, and often easier to operate. GraphQL is the better choice when the client needs flexibility, when you want to avoid multiple round trips, or when your backend consists of many microservices that need to be combined behind one API. 
    </p>

    <p class="question">Explain @Transactional in spring boot</p>
    <p class="answer"><span style="background-color: aliceblue;">@Transactional</span> defines a transaction boundary around a method. Everything inside that method forms one atomic unit of work, meaning all operations commit together or all roll back together. Spring manages this automatically by starting a transaction when the method begins and ending it when the method finishes. Two attributes&mdash;propagation and isolation&mdash;control how transactions behave when methods call each other and how concurrent transactions view data.<br><b>Propagation</b><br>Propagation determines what Spring should do when a transactional method is called from another method.<br>Let's use this example: Suppose <span style="background-color: ghostwhite;">MethodA</span> performs some database write operation (say it: dbA operation). Inside MethodA, you call MethodB, and MethodB performs a database write operation (say it dbB operation). During its execution, MethodB throws an exception. Depending on the propagation setting, Spring decides whether MethodB should join MethodA's transaction, start its own, or avoid transactions altogether. This choice determines whether dbA's changes, dbB's changes, or both get committed or rolled back.<br>Now each propagation behavior works like this:
    <ul style="margin: 0px;">
        <li><b style="font-size: 93%;">REQUIRED:</b> If MethodA has a transaction, MethodB joins it and both dbA and dbB roll back when MethodB throws. If MethodA has no transaction, MethodB creates one; dbB rolls back on exception, while dbA remains committed because it was autocommitted.</li>
        <li><b style="font-size: 93%;">SUPPORTS:</b> If MethodA has a transaction, MethodB joins and both roll back. If MethodA is non-transactional, MethodB also runs without one and both dbA and dbB changes stay committed because there is no transaction to roll back.</li>
        <li><b style="font-size: 93%;">MANDATORY:</b> MethodA must already have an active transaction. If MethodA has one, MethodB joins and both roll back on exception. If MethodA has no transaction, Spring throws IllegalTransactionStateException immediately before executing MethodB.</li>
        <li><b>REQUIRES_NEW:</b> MethodB always creates its own new transaction. If MethodA had one, it is suspended. MethodB rolls back dbB, but MethodA can still commit dbA normally.</li>
        <li><b style="font-size: 93%;">NOT_SUPPORTED:</b> If MethodA has a transaction, it is suspended. MethodB runs without a transaction and dbB changes are usually autocommitted even if an exception occurs. MethodA's transaction resumes later to commit or roll back dbA independently.</li>
        <li><b style="font-size: 93%;">NEVER:</b> MethodB must not run within a transaction. If MethodA has an active transaction, Spring throws IllegalTransactionStateException before running MethodB. If MethodA is non-transactional, MethodB runs without a transaction and dbB stays committed.</li>
        <li><b style="font-size: 93%;">NESTED:</b> MethodB runs inside a savepoint of MethodA's transaction. If MethodB throws, only the dbB changes roll back to the savepoint while dbA remains untouched. If MethodA later fails, everything rolls back including MethodB's rolled-back work.</li>
    </ul>
    <b>Isolation</b><br>Isolation defines what your transaction can see when other transactions read or write the same data concurrently.<br>
    Again, imagine MethodA and MethodB running at the same time, but now focus on reading/writing interactions. MethodA might read some data from dbA table while MethodB updates or inserts data in dbA table at the same time. Depending on the isolation level, MethodA may or may not see MethodB's changes, and it may or may not see new rows created by MethodB during its own transaction.<br>Each isolation level behaves like this:
    <ul style="margin: 0px;">
        <li><b style="font-size: 93%;">DEFAULT:</b> Uses the database's default isolation setting, usually READ_COMMITTED.</li>
        <li><b style="font-size: 93%;">READ_UNCOMMITTED:</b> MethodA can see MethodB's uncommitted writes. Dirty reads are possible, making this the least safe.</li>
        <li><b style="font-size: 93%;">READ_COMMITTED:</b> MethodA sees MethodB's changes only after MethodB commits. Prevents dirty reads but allows non-repeatable reads.</li>
        <li><b style="font-size: 93%;">REPEATABLE_READ:</b> Once MethodA reads a row, it continues to see the same version of that row even if MethodB commits updates later. This prevents dirty reads and non-repeatable reads. However, phantom reads can still occur. A phantom read means MethodA runs a query twice and, on the second run, sees newly inserted rows that match the same query criteria, even though existing rows remain stable.</li>
        <li><b style="font-size: 93%;">SERIALIZABLE:</b> Strictest isolation. MethodA and MethodB behave as if executed one after another. Prevents dirty reads, non-repeatable reads, and phantom reads, but reduces concurrency and may cause more locking or retries.</li>
    </ul>
    </p>
    <p class="question">Why volatile is not enough to make an operation thread safe in java?</p>
    <p class="answer">volatile in Java guarantees visibility, not atomicity, and that difference is exactly why volatile alone cannot make most operations thread-safe.<br>When you mark a variable as volatile, you ensure that whenever one thread writes to it, other threads immediately see the updated value. The value is always read from and written to main memory, not CPU caches, so threads don't work on stale copies. But this visibility guarantee does not mean the whole operation involving that variable is safe. Most real operations require more than just reading or writing a single value—they involve multiple steps, and that's where volatile breaks down.<br>A non-atomic operation like count++ is actually three separate actions: read the current value, add one, and write the new value back. Even if count is volatile, two threads can read the same value at the same time, both compute the same result, and both write back the same value. The <q>lost update</q> problem still occurs because volatile does not protect the critical section. The visibility rule only ensures the read and write hit main memory, but it does not ensure that the sequence of multiple steps happens as one indivisible unit.<br>Thread safety usually requires atomicity, mutual exclusion, or coordination. Operations like incrementing a counter, modifying collections, updating shared state, or checking-then-acting patterns need some form of locking or atomic classes because they require the entire sequence to execute without interference. synchronized or ReentrantLock ensures only one thread can perform the sequence at a time. Atomic classes like AtomicInteger use low-level CAS instructions to make multi-step updates act like a single atomic operation.</p>
    <p class="question">Difference between CopyOnWriteArrayList and Collections.synchronizedList(...)</p>
    <p class="answer">Collections.synchronizedList(list) wraps a normal List and synchronizes every operation using a single lock. This means every read and write acquires the same monitor lock. The benefit is that all operations are thread-safe, and modifications behave just like a normal list. But the downside is that heavy contention builds up under concurrent access. Multiple threads cannot read the list at the same time; they must take turns, which limits scalability. Iteration requires manual synchronization on the list to avoid ConcurrentModificationException. This approach is best when you have frequent writes and the list size is moderate, because modifications remain efficient and inexpensive.<br>CopyOnWriteArrayList takes a completely different approach. Instead of locking for reads, it allows concurrent readers to access the underlying array without locking at all. When a write operation occurs—like add, set, or remove—the list creates a new copy of the entire backing array, applies the modification, and replaces the reference. Reads are fast and never blocked, iteration never throws modification exceptions, and snapshots remain consistent. The trade-off is that writes are extremely expensive because copying the whole array is O(n) every time. This makes it a great fit for read-heavy workloads with very infrequent writes, especially when thread-safe iteration is important.<br>If your workload has many readers and very few updates, CopyOnWriteArrayList offers excellent scalability and nearly lock-free behavior for reads. You avoid locking overhead and get safe, consistent iterators. If your workload has frequent writes, or if the list is large, synchronizedList is a better choice because it doesn't require copying the entire underlying data structure on each modification. You pay for lock contention on reads, but writes remain efficient and predictable. Thus, the right choice depends on whether your system is dominated by reads or writes and how large you expect the list to grow.</p>
</body>
</html>